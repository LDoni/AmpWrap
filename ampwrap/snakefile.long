import os
from datetime import datetime

# Configure input output directories
latency_wait = 20
input_dir = config["input_dir"]
output_dir = config["output_dir"]
sample_names = config["sample_names"]
print(sample_names)
file_extension = config["file_extension"]
trimming_method = config.get("trimming_method")
tax_db = config["tax_db"]
db_dir = config.get("db_dir",f"db_s/emu/{tax_db}")
rank = config.get("rank", None)
cpus = int(config["threads"])
#to_cutadapt = all(p in config and config[p] not in [None, ""] for p in ["forward_primer", "reverse_primer"])
chimera = config.get("chimera", None)
suffix = "scrubbed" if chimera else "nanofilt"
keepcounts = "" if not config.get("keep_counts",False) else "--keep-counts"



to_cutadapt = all(
    p in config and config[p] not in [None, "", "null", "None"]
    for p in ["forward_primer", "reverse_primer"]
)


forward_primer = config.get("forward_primer")
reverse_primer = config.get("reverse_primer")

def getCutAdaptInput(wildcards):
        if trimming_method == None: return({"fq":f"{input_dir}/{wildcards.sample}.{file_extension}"})
        return({"fq":f"{output_dir}/intermediate/porechop/{wildcards.sample}-porechop.fastq.gz"})

def getNanoFiltInput(wildcards):
        raw_sample = wildcards.sample.replace("-nanofilt", "")
        if to_cutadapt == True: return({"fq":f"{output_dir}/intermediate/cutadapt/{raw_sample}_cutadapt.fq.gz"})
        else:
            if trimming_method != None: return({"fq":f"{output_dir}/intermediate/porechop/{raw_sample}-porechop.fastq.gz"})
            else: return({"fq":f"{input_dir}/{raw_sample}.{file_extension}"})

def getEmuInput(wildcards):
        if chimera == True: return({"fastq":f"{output_dir}/intermediate/nanofilt/{wildcards.sample}-scrubbed.fastq"})
        else: return({"fastq":f"{output_dir}/intermediate/nanofilt/{wildcards.sample}-nanofilt.fastq"})

# nanofilt parameters
nl_min_len = config.get("nl_min_len",1200)
nl_max_len = config.get("nl_max_len",1800)
nl_min_qual = config.get("nl_min_qual",10)

# emu parameters

emu_min_ab = config.get("emu_min_ab", 0.0001)

def reverse_complement(seq):
    if seq is None:
        return None
    from Bio.Seq import Seq
    seq = Seq(seq)
    return seq.reverse_complement()

RC_FWD = reverse_complement(forward_primer) if forward_primer else None
RC_RVS = reverse_complement(reverse_primer) if reverse_primer else None




start_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
print(start_time)


rule all:
    input:
        # QC initial
        expand(f"{config['output_dir']}/QC/raw_qc_initial/{{sample}}_fastqc.html", sample = sample_names),
        f"{config['output_dir']}/QC/raw_qc_initial/readcount/raw_reads_counts.txt",
        f"{config['output_dir']}/QC/raw_qc_initial/multiqc_report.html",
        #Porechop
        expand(f"{config['output_dir']}/intermediate/porechop/{{sample}}-porechop.fastq.gz", sample=sample_names) if trimming_method != None else [],
        #Cutadapt
        expand(f"{config['output_dir']}/intermediate/cutadapt/{{sample}}_cutadapt.fq.gz", sample=sample_names) if to_cutadapt else [],
        f"{config['output_dir']}/intermediate/cutadapt/cutadapt_primer_trimming_stats.txt" if to_cutadapt else [],
        #Qc post
        expand(f"{config['output_dir']}/QC/raw_qc_post/{{sample}}-nanofilt_fastqc.html", sample=sample_names),
        f"{config['output_dir']}/QC/raw_qc_post/multiqc_report.html",
        f"{config['output_dir']}/QC/raw_qc_post/readcount/filtered_reads_counts.txt",
        expand(f"{config['output_dir']}/intermediate/nanofilt/{{sample}}-{suffix}.fastq", sample=sample_names) if chimera else [],
        #emuDB
        f"{db_dir}",
        expand("{db_dir}/{tax_file}",db_dir=db_dir,tax_file=["taxonomy.tsv","species_taxid.fasta"]),
        #emu
        expand(f"{output_dir}/results/emu/{{sample}}-{suffix}_rel-abundance.tsv", sample=sample_names),
        #handoff
        f"{output_dir}/results/emu/emu_phyloseq.rds",
        f"{output_dir}/results/emu/emu_abundance.biom",
        #final report
        f"{config['output_dir']}/results/final_report.txt"


rule seqkit_stats_pre_qc:
    input:
        expand("{input_dir}/{sample}.{file_extension}",
               input_dir=input_dir,
               sample=sample_names,
               file_extension=file_extension)
    output:
        "{output_dir}/QC/raw_qc_initial/readcount/raw_reads_counts.txt"
    shell:
        """
        mkdir -p $(dirname {output})
        seqkit stats -T -j {threads} {input_dir}/*.{file_extension} > {output}
        """

rule fastqc_initial:
    input:
        f"{input_dir}/{{sample}}.{file_extension}"
    output:
        "{output_dir}/QC/raw_qc_initial/{sample}_fastqc.html"
    shell:
        """
        mkdir -p {output_dir}/QC/raw_qc_initial
        fastqc {input} -o $(dirname {output})  > /dev/null 2>&1
        """

rule multiqc_initial:
    input: expand("{output_dir}/QC/raw_qc_initial/{sample}_fastqc.html",output_dir=output_dir,sample=sample_names)
    output: f"{output_dir}/QC/raw_qc_initial/multiqc_report.html"
    shell:
        """
        multiqc $(dirname {output}) -o $(dirname {output}) > /dev/null 2>&1
        """

rule porechop:
    input:
        f"{input_dir}/{{sample}}.{file_extension}"
    output:
        fq="{output_dir}/intermediate/porechop/{sample}-porechop.fastq.gz"
    run:
        if trimming_method == "porechop_abi":
            cmd = f"porechop_abi -abi -i {input} -o {output.fq}"
        elif trimming_method == "porechop":
            cmd = f"porechop -i {input} -o {output.fq}"
        else:
            raise ValueError(f"Unsupported trimming_method: {trimming_method}")

        shell(f"""
            mkdir -p {output_dir}/intermediate/porechop
            {cmd} > /dev/null 2>&1
        """)


rule cutadapt_primers:
    input: unpack(getCutAdaptInput)
    output:
        r1_trimmed = "{output_dir}/intermediate/cutadapt/{sample}_cutadapt.fq.gz",
    log:
        "{output_dir}/intermediate/cutadapt/{sample}_cutadapt.log"
    params:
        forward_primer = forward_primer,
        reverse_primer = reverse_primer,
        RC_RVS = RC_RVS,

    shell:
      """
      mkdir -p {output_dir}/intermediate/cutadapt
      cutadapt -e 0.2 -O 15 --revcomp -o {output.r1_trimmed} -a {params.forward_primer}...{params.RC_RVS} {input.fq} > {log}
      """


rule combine_cutadapt_logs:
    input: expand("{output_dir}/intermediate/cutadapt/{sample}_cutadapt.log", output_dir=output_dir, sample=sample_names)
    output: f"{output_dir}/intermediate/cutadapt/cutadapt_primer_trimming_stats.txt"
    log: f"{output_dir}/intermediate/cutadapt/combined_cutadapt.log"
    shell:
         f"""
        cat {{input}} > {{output}}
        echo -e "sample\treads retained\tbps retained" > {{log}}
        paste <(echo {" ".join(list(sample_names))} | tr " " "\n") <(grep "passing" {{output}} | cut -f3 -d "(" | tr -d ")") <(grep "filtered" {{output}} | cut -f3 -d "(" | tr -d ")") >> {{log}}
        cat {{log}}
        mkdir -p "{output_dir}/QC/raw_qc_post/"
        mv {{input}} "{output_dir}/QC/raw_qc_post/"
          """

rule nanofilt:
    input:
        unpack(getNanoFiltInput)
    output:
        fq="{output_dir}/intermediate/nanofilt/{sample}-nanofilt.fastq"
    shell:
        f"""
        mkdir -p {{output_dir}}/intermediate/nanofilt
        if [[ "{{input.fq}}" == *.gz ]]; then
            zcat {{input.fq}} | NanoFilt -l {nl_min_len} --maxlength {nl_max_len} -q {nl_min_qual} > {{output.fq}}
        else
            cat {{input.fq}} | NanoFilt -l {nl_min_len} --maxlength {nl_max_len} -q {nl_min_qual} > {{output.fq}}
        fi
        """

rule fastqc_post:
    input:
        trimmed_files = "{output_dir}/intermediate/nanofilt/{sample}-nanofilt.fastq"
    output:
        fastqc = "{output_dir}/QC/raw_qc_post/{sample}-nanofilt_fastqc.html"
    shell:
        """
        mkdir -p $(dirname {output})
        fastqc {input.trimmed_files} -o $(dirname {output})  > /dev/null 2>&1
        """

rule multiqc_post:
    input: expand("{output_dir}/QC/raw_qc_post/{sample}-nanofilt_fastqc.html",output_dir=output_dir,sample=sample_names)
    output: "{output_dir}/QC/raw_qc_post/multiqc_report.html"
    shell:
        """
        multiqc $(dirname {output}) -o $(dirname {output})  > /dev/null 2>&1
        """

rule chimera_scrub:
    input:
        fq="{output_dir}/intermediate/nanofilt/{sample}-nanofilt.fastq"
    output:
        fq="{output_dir}/intermediate/nanofilt/{sample}-scrubbed.fastq",
    threads:
        cpus
    params:
        paf="{output_dir}/intermediate/nanofilt/{sample}.paf",
        yacrd="{output_dir}/intermediate/nanofilt/{sample}.yacrd"
    shell:
        """
        minimap2 -x ava-ont -g 500 -t {threads} {input.fq} {input.fq} > {params.paf}
        yacrd -i {params.paf} -o {params.yacrd} -c 4 -n 0.4 scrubb -i {input.fq} -o {output.fq}
        rm {params.paf}
        """

rule seqkit_stats_post_qc:
    input:
        expand("{output_dir}/intermediate/nanofilt/{sample}-{suffix}.fastq",
               output_dir=output_dir,
               sample=sample_names,
               suffix=suffix)
    output:
        "{output_dir}/QC/raw_qc_post/readcount/filtered_reads_counts.txt"
    shell:
        """
        mkdir -p $(dirname {output})
        seqkit stats -T -j {cpus} {output_dir}/intermediate/nanofilt/*-{suffix}.fastq > {output}
        """


#rule emu_database:
#    output:
#        the_dir=directory(f"{db_dir}"),
#        taxonomy=f"{db_dir}/taxonomy.tsv",
#        taxids=f"{db_dir}/species_taxid.fasta"
#    params:
#        md5_dict={
#            "emu": "707f235f515c0dc2e8d74278294241e7",
#            "rdp": "5aebf4f791d32950bfa07e5e0e7ea22a",
#            "silva": "4195810ceec63ed13b9ee3f9c678c52b"
#        }
#    run:
#        import os
#        db_tar = f"{db_dir}/{tax_db}.tar"
#        os.makedirs(output.the_dir, exist_ok=True)

        # download file
#        shell(f"osf -p 56uf7 fetch osfstorage/emu-prebuilt/{tax_db}.tar {db_tar}")

        # MD5 check
#        expected_md5 = params.md5_dict[tax_db]
#        import subprocess
#        result = subprocess.run(f"echo '{expected_md5}  {db_tar}' | md5sum -c -", shell=True)
#        if result.returncode != 0:
#            raise ValueError(f"ERROR: MD5 checksum failed for {db_tar}")

        #  tar extraction
#        shell(f"tar -xvf {db_tar} -C {output.the_dir} > /dev/null 2>&1")


rule emu_database:
    output:
        the_dir=directory(f"{db_dir}"),
        taxonomy=f"{db_dir}/taxonomy.tsv",
        taxids=f"{db_dir}/species_taxid.fasta"
    params:
        md5_dict={
            "emu": "707f235f515c0dc2e8d74278294241e7",
            "rdp": "5aebf4f791d32950bfa07e5e0e7ea22a",
            "silva": "4195810ceec63ed13b9ee3f9c678c52b",
            "pr2": "51e1c9eb383e8770d1ccdf805b35444f"
        }
    run:
        import os
        import subprocess
        os.makedirs(output.the_dir, exist_ok=True)

        if tax_db == "pr2":
            db_zip = f"{db_dir}/pr2_version_5.1.1_emu.zip"
            db_url = "https://github.com/pr2database/pr2database/releases/download/v5.1.1/pr2_version_5.1.1_emu.zip"

            shell(f"wget -O {db_zip} {db_url}")
            # md5 check
            expected_md5 = params.md5_dict["pr2"]
            result = subprocess.run(f"echo '{expected_md5}  {db_zip}' | md5sum -c -", shell=True)
            if result.returncode != 0:
                raise ValueError(f"ERROR: MD5 checksum failed for {db_zip}")
            # unzip
            shell(f"unzip -o {db_zip} -d {output.the_dir}")

        else:
            db_tar = f"{db_dir}/{tax_db}.tar"
            shell(f"osf -p 56uf7 fetch osfstorage/emu-prebuilt/{tax_db}.tar {db_tar}")
            # md5 check
            expected_md5 = params.md5_dict[tax_db]
            result = subprocess.run(f"echo '{expected_md5}  {db_tar}' | md5sum -c -", shell=True)
            if result.returncode != 0:
                raise ValueError(f"ERROR: MD5 checksum failed for {db_tar}")

            shell(f"tar -xvf {db_tar} -C {output.the_dir} > /dev/null 2>&1")


rule emu_abundance:
    input:
        unpack(getEmuInput)
    output:
        "{output_dir}/results/emu/{sample}-{suffix}_rel-abundance.tsv",
    params:
        type='map-ont',
        min_ab=emu_min_ab,
        db=lambda wildcards: f"db_s/emu/{config['tax_db']}",
        keepcounts=keepcounts
    threads:
        cpus
    shell:
        """
        mkdir -p {output_dir}/results/emu
        echo emu abundance {input} --output-dir {output_dir}/results/emu --db {params.db} --threads {threads} --min-abundance {params.min_ab} {params.keepcounts}
        emu abundance {input} --output-dir {output_dir}/results/emu --db {params.db} --threads {threads} --min-abundance {params.min_ab} {params.keepcounts}
        """

rule emu_phyloseq:
    input:
        expand("{output_dir}/results/emu/{sample}-{suffix}_rel-abundance.tsv",
               output_dir=output_dir, sample=sample_names, suffix=suffix)
    output:
        "{output_dir}/results/emu/emu_phyloseq.rds",
        "{output_dir}/results/emu/emu_abundance.biom"
    params:
        emu_dir=lambda wildcards: f"{output_dir}/results/emu"
    script:
        "scripts/emu_handoff.R"

rule reporter:
    input:
        seqkit_pre = f"{config['output_dir']}/QC/raw_qc_initial/readcount/raw_reads_counts.txt",
        seqkit_post = f"{config['output_dir']}/QC/raw_qc_post/readcount/filtered_reads_counts.txt",
        emu_results = expand(
            "{output_dir}/results/emu/{sample}-{suffix}_rel-abundance.tsv",
            output_dir=config['output_dir'],
            sample=config['sample_names'],
            suffix=suffix
        ),
        **({ "cutadapt": f"{config['output_dir']}/intermediate/cutadapt/combined_cutadapt.log" } if to_cutadapt else {})
    output:
        report = f"{config['output_dir']}/results/final_report.txt"
    params:
        config.get("trimming_method"),
        nl_min_qual = config["nl_min_qual"],
        nl_min_len = config["nl_min_len"],
        nl_max_len = config["nl_max_len"],
        emu_min_ab = config["emu_min_ab"],
        forward_p = config.get("forward_primer"),
        reverse_p = config.get("reverse_primer"),
        RC_FWD = config.get("RC_FWD"),
        RC_RVS = config.get("RC_RVS"),
        start = start_time,
        tax_db = config["tax_db"],
        to_cutadapt = to_cutadapt,
        trimming_method = trimming_method
    script:
        "scripts/reporter_long.py"
